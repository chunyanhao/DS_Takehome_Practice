{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002d2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f44c44",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdabe0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records:\t 77677\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/ChunyanHao/desktop/github/ds_take_home/data/url_list.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print('Total Records:\\t', len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416357fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_search(lines):\n",
    "    \"\"\" function to parse user's search history \"\"\"\n",
    "    length = len(lines)\n",
    "    names = ['checkin', 'checkout', 'customMinimumPriceFilter', \n",
    "             'customMaximumPriceFilter', 'freeCancellation', 'stars_5', \n",
    "             'stars_4', 'stars_3', 'stars_2', 'stars_1', 'max_score', \n",
    "             'min_score', 'couponCode', 'adults', 'city', 'children', \n",
    "             'amenities', 'search_page']\n",
    "    \n",
    "    maps = {}\n",
    "    for name in names:\n",
    "        maps[name] = [np.nan] * length\n",
    "      \n",
    "    for i in range(length):\n",
    "        line = lines[i]\n",
    "        items = line[50:].strip().split('&')\n",
    "        visited = set()\n",
    "        for item in items:\n",
    "            key, value = item.strip().split('=')\n",
    "            key = key.strip().split('.')[1]\n",
    "            if key == 'city':\n",
    "                value = value.strip().replace('+', ' ')\n",
    "            if key not in visited:\n",
    "                maps[key][i] = value\n",
    "                visited.add(key)\n",
    "            else:\n",
    "                maps[key][i] = maps[key][i] + ', ' + value\n",
    "            \n",
    "    # transform into DataFrame\n",
    "    df = pd.DataFrame(maps, columns=names)\n",
    "    df['checkin'] = pd.to_datetime(df['checkin'])\n",
    "    df['checkout'] = pd.to_datetime(df['checkout'])\n",
    "    df = df.rename(columns={'customMinimumPriceFilter': 'MinPrice', \n",
    "                            'customMaximumPriceFilter': 'MaxPrice'})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a39e878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkin</th>\n",
       "      <th>checkout</th>\n",
       "      <th>MinPrice</th>\n",
       "      <th>MaxPrice</th>\n",
       "      <th>freeCancellation</th>\n",
       "      <th>stars_5</th>\n",
       "      <th>stars_4</th>\n",
       "      <th>stars_3</th>\n",
       "      <th>stars_2</th>\n",
       "      <th>stars_1</th>\n",
       "      <th>max_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>couponCode</th>\n",
       "      <th>adults</th>\n",
       "      <th>city</th>\n",
       "      <th>children</th>\n",
       "      <th>amenities</th>\n",
       "      <th>search_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-09-19</td>\n",
       "      <td>2015-09-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>New York, NY, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-09-14</td>\n",
       "      <td>2015-09-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-26</td>\n",
       "      <td>2015-09-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>New York, NY, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     checkin   checkout MinPrice MaxPrice freeCancellation stars_5 stars_4  \\\n",
       "0 2015-09-19 2015-09-20      NaN      NaN              NaN     NaN     yes   \n",
       "1 2015-09-14 2015-09-15      NaN      NaN              NaN     NaN     NaN   \n",
       "2 2015-09-26 2015-09-27      NaN      175              NaN     NaN     yes   \n",
       "\n",
       "  stars_3 stars_2 stars_1 max_score min_score couponCode adults  \\\n",
       "0     NaN     NaN     NaN       NaN         4        NaN      3   \n",
       "1     yes     NaN     NaN       NaN         4        NaN      3   \n",
       "2     NaN     NaN     NaN       NaN         5        NaN      2   \n",
       "\n",
       "                          city children amenities search_page  \n",
       "0  New York, NY, United States      NaN       NaN           1  \n",
       "1       London, United Kingdom      NaN       NaN           1  \n",
       "2  New York, NY, United States      NaN       NaN           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = parse_search(lines)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f82378",
   "metadata": {},
   "source": [
    "### 2. For each search query, how many amenities were selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aa00eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "internet                272\n",
       "yes_smoking             170\n",
       "shuttle                 111\n",
       "yes_pet                  85\n",
       "breakfast                39\n",
       "lounge                   22\n",
       "yes_smoking, yes_pet      4\n",
       "breakfast, yes_pet        1\n",
       "Name: amenities, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.amenities.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "213c5e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    76973\n",
       "1      699\n",
       "2        5\n",
       "Name: amenities, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['amenities'].apply(lambda x: 0 if pd.isnull(x)  else len(x.split(', '))).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55575ea",
   "metadata": {},
   "source": [
    "### 3.\n",
    "\n",
    "Often, to measure the quality of a search algorithm, data scientists use some metric based on how often users click on the second page, third page, and so on. The idea here is that a great search algorithm should return all interesting results on the first page and never force users to visit the other pages (how often do you click on the second page results when you search on Google? Almost never, right?).\n",
    "\n",
    "Create a metric based on the above idea and find the city with the worst search algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438c64f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     64.369118\n",
       "2     14.981269\n",
       "3      7.549210\n",
       "4      4.679635\n",
       "5      3.118040\n",
       "6      2.106158\n",
       "7      1.434144\n",
       "8      0.952663\n",
       "9      0.561299\n",
       "10     0.248465\n",
       "Name: search_page, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*data['search_page'].value_counts()/len(data['search_page'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc54e8",
   "metadata": {},
   "source": [
    "For each city, we can calculate the percentage of search with page = 1 as an idea metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f0e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['page_1'] = data['search_page'] == '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e30760f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "Hong Kong, Hong Kong                        0.910826\n",
       "London, United Kingdom                      0.526588\n",
       "New York, NY, United States                 0.557616\n",
       "San Francisco, California, United States    0.959285\n",
       "Name: page_1, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['city'])['page_1'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9188c2cf",
   "metadata": {},
   "source": [
    "It's clear that 'London, United Kingdom' has the lowest percentage of search with page = 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
